{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_o3dYMu2V0fX"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.keras.layers import Conv2D\n",
        "from tensorflow.keras.layers import MaxPooling2D\n",
        "from tensorflow.keras.layers import Dropout \n",
        "from tensorflow.keras.layers import Conv2DTranspose\n",
        "from tensorflow.keras.layers import concatenate\n",
        "\n",
        "import os\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1cqDkSc_WjEi"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np \n",
        "import pandas as pd \n",
        "\n",
        "import imageio\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "\n",
        "path = '/Users/abdulmateen/Downloads/car-segmentation' \n",
        "image_path = os.path.join(path, './images')\n",
        "mask_path = os.path.join(path, './masks')\n",
        "image_list = os.listdir(image_path)\n",
        "mask_list = os.listdir(mask_path)\n",
        "image_list = [image_path+\"/\"+i for i in image_list]\n",
        "mask_list = [mask_path+\"/\"+i for i in mask_list]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lt9uB2RxwRzS"
      },
      "outputs": [],
      "source": [
        "N = 9\n",
        "img = imageio.imread(image_list[N])\n",
        "mask = imageio.imread(mask_list[N])\n",
        "#mask = np.array([max(mask[i, j]) for i in range(mask.shape[0]) for j in range(mask.shape[1])]).reshape(img.shape[0], img.shape[1])\n",
        "\n",
        "fig, arr = plt.subplots(1, 2, figsize=(14, 10))\n",
        "arr[0].imshow(img)\n",
        "arr[0].set_title('Image')\n",
        "arr[1].imshow(mask)\n",
        "arr[1].set_title('Segmentation')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Splitting the dataset into masked and unmasked images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RnWC8uwJwV2p"
      },
      "outputs": [],
      "source": [
        "image_list_ds = tf.data.Dataset.list_files(image_list, shuffle=False)\n",
        "mask_list_ds = tf.data.Dataset.list_files(mask_list, shuffle=False)\n",
        "\n",
        "for path in zip(image_list_ds.take(3), mask_list_ds.take(3)):\n",
        "    print(path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "efJb7v7KwZhf"
      },
      "outputs": [],
      "source": [
        "image_filenames = tf.constant(image_list)\n",
        "masks_filenames = tf.constant(mask_list)\n",
        "\n",
        "dataset = tf.data.Dataset.from_tensor_slices((image_filenames, masks_filenames))\n",
        "\n",
        "for image, mask in dataset.take(1):\n",
        "    print(image)\n",
        "    print(mask)\n",
        "\n",
        "type(dataset)\n",
        "dataset.m\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Preprocessing the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mfvfNJkNwckl"
      },
      "outputs": [],
      "source": [
        "# Setting the images between 0 and 1\n",
        "def process_path(image_path, mask_path):\n",
        "    img = tf.io.read_file(image_path)\n",
        "    img = tf.image.decode_png(img, channels=3)\n",
        "    img = tf.image.convert_image_dtype(img, tf.float32)\n",
        "\n",
        "    mask = tf.io.read_file(mask_path)\n",
        "    mask = tf.image.decode_png(mask, channels=3)\n",
        "    mask = tf.math.reduce_max(mask, axis=-1, keepdims=True)\n",
        "    return img, mask\n",
        "\n",
        "def preprocess(image, mask):\n",
        "    input_image = tf.image.resize(image, (96, 128), method='nearest')\n",
        "    input_mask = tf.image.resize(mask, (96, 128), method='nearest')\n",
        "\n",
        "    return input_image, input_mask\n",
        "\n",
        "image_ds = dataset.map(process_path)\n",
        "processed_image_ds = image_ds.map(preprocess)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for im,mks in processed_image_ds.take(1):\n",
        "    print(im)\n",
        "    print(mks)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "U-Net architecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3SiWAuevQ_ZK"
      },
      "outputs": [],
      "source": [
        "\n",
        "def conv_block(inputs=None, n_filters=32, dropout_prob=0, max_pooling=True):\n",
        "    \"\"\"\n",
        "    Convolutional downsampling block\n",
        "    \n",
        "    Arguments:\n",
        "        inputs -- Input tensor\n",
        "        n_filters -- Number of filters for the convolutional layers\n",
        "        dropout_prob -- Dropout probability\n",
        "        max_pooling -- Use MaxPooling2D to reduce the spatial dimensions of the output volume\n",
        "    Returns: \n",
        "        next_layer, skip_connection --  Next layer and skip connection outputs\n",
        "    \"\"\"\n",
        "\n",
        "    conv = Conv2D(filters=n_filters, \n",
        "                  kernel_size=3,     \n",
        "                  activation='relu',\n",
        "                  padding='same',\n",
        "                  kernel_initializer='he_normal')(inputs)\n",
        "    conv = Conv2D(filters=n_filters, \n",
        "                  kernel_size=3,    \n",
        "                  activation='relu',\n",
        "                  padding='same',\n",
        "                  kernel_initializer='he_normal')(conv)\n",
        "    \n",
        "    # if dropout_prob > 0 add a dropout layer, with the variable dropout_prob as parameter\n",
        "    if dropout_prob > 0:\n",
        "        conv = Dropout(dropout_prob)(conv)\n",
        "         \n",
        "        \n",
        "    # if max_pooling is True add a MaxPooling2D with 2x2 pool_size\n",
        "    if max_pooling:\n",
        "        next_layer = MaxPooling2D(2,2)(conv)\n",
        "        \n",
        "    else:\n",
        "        next_layer = conv\n",
        "        \n",
        "    skip_connection = conv\n",
        "    \n",
        "    return next_layer, skip_connection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BFBTtGxcTYF9"
      },
      "outputs": [],
      "source": [
        "# input_size=(96, 128, 3)\n",
        "# n_filters = 32\n",
        "# inputs = Input(input_size)\n",
        "# cblock1 = conv_block(inputs, n_filters * 1)\n",
        "# model1 = tf.keras.Model(inputs=inputs, outputs=cblock1)\n",
        "\n",
        "# output1 = [['InputLayer', [(None, 96, 128, 3)], 0],\n",
        "#             ['Conv2D', (None, 96, 128, 32), 896, 'same', 'relu', 'HeNormal'],\n",
        "#             ['Conv2D', (None, 96, 128, 32), 9248, 'same', 'relu', 'HeNormal'],\n",
        "#             ['MaxPooling2D', (None, 48, 64, 32), 0, (2, 2)]]\n",
        "\n",
        "# print('Block 1:')\n",
        "# # for layer in summary(model1):\n",
        "# #     print(layer)\n",
        "\n",
        "# # comparator(summary(model1), output1)\n",
        "\n",
        "# inputs = Input(input_size)\n",
        "# cblock1 = conv_block(inputs, n_filters * 32, dropout_prob=0.1, max_pooling=True)\n",
        "# model2 = tf.keras.Model(inputs=inputs, outputs=cblock1)\n",
        "\n",
        "# output2 = [['InputLayer', [(None, 96, 128, 3)], 0],\n",
        "#             ['Conv2D', (None, 96, 128, 1024), 28672, 'same', 'relu', 'HeNormal'],\n",
        "#             ['Conv2D', (None, 96, 128, 1024), 9438208, 'same', 'relu', 'HeNormal'],\n",
        "#             ['Dropout', (None, 96, 128, 1024), 0, 0.1],\n",
        "#             ['MaxPooling2D', (None, 48, 64, 1024), 0, (2, 2)]]\n",
        "           \n",
        "# print('\\nBlock 2:')   \n",
        "# for layer in summary(model2):\n",
        "#     print(layer)\n",
        "    \n",
        "# comparator(summary(model2), output2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GX7qvU14TalK"
      },
      "outputs": [],
      "source": [
        "\n",
        "def upsampling_block(expansive_input, contractive_input, n_filters=32):\n",
        "    \"\"\"\n",
        "    Convolutional upsampling block\n",
        "    \n",
        "    Arguments:\n",
        "        expansive_input -- Input tensor from previous layer\n",
        "        contractive_input -- Input tensor from previous skip layer\n",
        "        n_filters -- Number of filters for the convolutional layers\n",
        "    Returns: \n",
        "        conv -- Tensor output\n",
        "    \"\"\"\n",
        "    \n",
        "    up = Conv2DTranspose(\n",
        "                 n_filters,   \n",
        "                 3,    \n",
        "                 strides=(2,2),\n",
        "                 padding='same')(expansive_input)\n",
        "    \n",
        "    # Merge the previous output and the contractive_input\n",
        "    merge = concatenate([up, contractive_input], axis=3)\n",
        "    conv = Conv2D(n_filters,   \n",
        "                 3,    \n",
        "                 activation='relu',\n",
        "                 padding='same',\n",
        "                 kernel_initializer='he_normal')(merge)\n",
        "    conv = Conv2D(n_filters,  \n",
        "                 3,   \n",
        "                 activation='relu',\n",
        "                 padding='same',\n",
        "                 kernel_initializer='he_normal')(conv)\n",
        "    \n",
        "    return conv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZUZxvBrLTden"
      },
      "outputs": [],
      "source": [
        "# input_size1=(12, 16, 256)\n",
        "# input_size2 = (24, 32, 128)\n",
        "# n_filters = 32\n",
        "# expansive_inputs = Input(input_size1)\n",
        "# contractive_inputs =  Input(input_size2)\n",
        "# cblock1 = upsampling_block(expansive_inputs, contractive_inputs, n_filters * 1)\n",
        "# model1 = tf.keras.Model(inputs=[expansive_inputs, contractive_inputs], outputs=cblock1)\n",
        "\n",
        "# output1 = [['InputLayer', [(None, 12, 16, 256)], 0],\n",
        "#             ['Conv2DTranspose', (None, 24, 32, 32), 73760],\n",
        "#             ['InputLayer', [(None, 24, 32, 128)], 0],\n",
        "#             ['Concatenate', (None, 24, 32, 160), 0],\n",
        "#             ['Conv2D', (None, 24, 32, 32), 46112, 'same', 'relu', 'HeNormal'],\n",
        "#             ['Conv2D', (None, 24, 32, 32), 9248, 'same', 'relu', 'HeNormal']]\n",
        "\n",
        "# print('Block 1:')\n",
        "# for layer in summary(model1):\n",
        "#     print(layer)\n",
        "\n",
        "# comparator(summary(model1), output1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IcDBaVyOTf04"
      },
      "outputs": [],
      "source": [
        "\n",
        "def unet_model(input_size=(96, 128, 3), n_filters=32, n_classes=5):\n",
        "    \"\"\"\n",
        "    Unet model\n",
        "    \n",
        "    Arguments:\n",
        "        input_size -- Input shape \n",
        "        n_filters -- Number of filters for the convolutional layers\n",
        "        n_classes -- Number of output classes\n",
        "    Returns: \n",
        "        model -- tf.keras.Model\n",
        "    \"\"\"\n",
        "    inputs = Input(input_size)\n",
        "    # Contracting Path (encoding)\n",
        "    # Add a conv_block with the inputs of the unet_ model and n_filters\n",
        "   \n",
        "    cblock1 = conv_block(inputs=inputs, n_filters=n_filters)\n",
        "    # Chain the first element of the output of each block to be the input of the next conv_block. \n",
        "    # Double the number of filters at each new step\n",
        "    cblock2 = conv_block(cblock1[0], n_filters=n_filters*2)\n",
        "    cblock3 = conv_block(cblock2[0], n_filters=n_filters*4)\n",
        "    cblock4 = conv_block(cblock3[0], n_filters=n_filters*8, dropout_prob=0.3) # Include a dropout_prob of 0.3 for this layer\n",
        "    # Include a dropout_prob of 0.3 for this layer, and avoid the max_pooling layer\n",
        "    cblock5 = conv_block(cblock4[0], n_filters=n_filters*16, dropout_prob=0.3, max_pooling=False) \n",
        "    \n",
        "    \n",
        "    # Expanding Path (decoding)\n",
        "    # Add the first upsampling_block.\n",
        "    # Use the cblock5[0] as expansive_input and cblock4[1] as contractive_input and n_filters * 8\n",
        "    \n",
        "    ublock6 = upsampling_block(cblock5[0], cblock4[1],  n_filters=n_filters*8)\n",
        "    # Chain the output of the previous block as expansive_input and the corresponding contractive block output.\n",
        "    # Note that you must use the second element of the contractive block i.e before the maxpooling layer. \n",
        "    # At each step, use half the number of filters of the previous block \n",
        "    ublock7 = upsampling_block(ublock6, cblock3[1],  n_filters=n_filters*4)\n",
        "    ublock8 = upsampling_block(ublock7, cblock2[1],  n_filters=n_filters*2)\n",
        "    ublock9 = upsampling_block(ublock8, cblock1[1],  n_filters=n_filters)\n",
        "    \n",
        "\n",
        "    conv9 = Conv2D(n_filters,\n",
        "                 3,\n",
        "                 activation='relu',\n",
        "                 padding='same',\n",
        "                 kernel_initializer='he_normal')(ublock9)\n",
        "\n",
        "    # Add a Conv2D layer with n_classes filter, kernel size of 1 and a 'same' padding\n",
        "    ### START CODE HERE\n",
        "    conv10 = Conv2D(n_classes, 1, padding='same')(conv9)\n",
        "    ### END CODE HERE\n",
        "    \n",
        "    model = tf.keras.Model(inputs=inputs, outputs=conv10)\n",
        "\n",
        "    return model"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Set model dimensions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lA7_clLRTige"
      },
      "outputs": [],
      "source": [
        "# import outputs\n",
        "img_height = 96\n",
        "img_width = 128\n",
        "num_channels = 3\n",
        "\n",
        "unet = unet_model((img_height, img_width, num_channels))\n",
        "# comparator(summary(unet), outputs.unet_model_output)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BuADtKF-TsPX"
      },
      "outputs": [],
      "source": [
        "unet.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hmU8NGQTTv-M"
      },
      "outputs": [],
      "source": [
        "unet.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bK91U64aTylX"
      },
      "outputs": [],
      "source": [
        "def display(display_list):\n",
        "    plt.figure(figsize=(15, 15))\n",
        "\n",
        "    title = ['Input Image', 'True Mask', 'Predicted Mask']\n",
        "\n",
        "    for i in range(len(display_list)):\n",
        "        plt.subplot(1, len(display_list), i+1)\n",
        "        plt.title(title[i])\n",
        "        plt.imshow(tf.keras.preprocessing.image.array_to_img(display_list[i]))\n",
        "        plt.axis('off')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2bmkxTF5Tzgy"
      },
      "outputs": [],
      "source": [
        "for image, mask in image_ds.take(1):\n",
        "    sample_image, sample_mask = image, mask\n",
        "    print(mask.shape)\n",
        "display([sample_image, sample_mask])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hoHUOIPoT6Wi"
      },
      "outputs": [],
      "source": [
        "EPOCHS = 100\n",
        "VAL_SUBSPLITS = 5\n",
        "BUFFER_SIZE = 500\n",
        "BATCH_SIZE = 32\n",
        "processed_image_ds.batch(BATCH_SIZE)\n",
        "train_dataset = processed_image_ds.cache().shuffle(BUFFER_SIZE).batch(BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "model_history = unet.fit(train_dataset, epochs=EPOCHS)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Create predicted masks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CAQlVoYxT8pq"
      },
      "outputs": [],
      "source": [
        "def create_mask(pred_mask):\n",
        "    pred_mask = tf.argmax(pred_mask, axis=-1)\n",
        "    pred_mask = pred_mask[..., tf.newaxis]\n",
        "    return pred_mask[0]"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Plotting model accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iNWE4FkVUBHm"
      },
      "outputs": [],
      "source": [
        "plt.plot(model_history.history[\"accuracy\"])"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Making pridictions and checking with true masked"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pShF2mAhUDxp"
      },
      "outputs": [],
      "source": [
        "def show_predictions(dataset=None, num=1):\n",
        "    \"\"\"\n",
        "    Displays the first image of each of the num batches\n",
        "    \"\"\"\n",
        "    if dataset:\n",
        "        for image, mask in dataset.take(num):\n",
        "            pred_mask = unet.predict(image)\n",
        "            display([image[0], mask[0], create_mask(pred_mask)])\n",
        "    else:\n",
        "        display([sample_image, sample_mask,\n",
        "             create_mask(unet.predict(sample_image[tf.newaxis, ...]))])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "show_predictions(train_dataset,6)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_product(x: int, y:int) -> int:\n",
        "    return x *y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "get_product('2',3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Blocks:\n",
        "    def conv_block(self,inputs=None, n_filters=32, dropout_prob=0, max_pooling=True):\n",
        "\n",
        "        \"\"\"\n",
        "        Convolutional downsampling block\n",
        "        \n",
        "        Arguments:\n",
        "            inputs -- Input tensor\n",
        "            n_filters -- Number of filters for the convolutional layers\n",
        "            dropout_prob -- Dropout probability\n",
        "            max_pooling -- Use MaxPooling2D to reduce the spatial dimensions of the output volume\n",
        "        Returns: \n",
        "            next_layer, skip_connection --  Next layer and skip connection outputs\n",
        "        \"\"\"\n",
        "        self.inputs = inputs\n",
        "        self.n_filters = n_filters\n",
        "        self.dropout_prob = dropout_prob\n",
        "        self.max_pooling = max_pooling\n",
        "\n",
        "        conv = Conv2D(filters=self.n_filters, \n",
        "                    kernel_size=3,     \n",
        "                    activation='relu',\n",
        "                    padding='same',\n",
        "                    kernel_initializer='he_normal')(self.inputs)\n",
        "        conv = Conv2D(filters=self.n_filters, \n",
        "                    kernel_size=3,    \n",
        "                    activation='relu',\n",
        "                    padding='same',\n",
        "                    kernel_initializer='he_normal')(conv)\n",
        "        \n",
        "        # if dropout_prob > 0 add a dropout layer, with the variable dropout_prob as parameter\n",
        "        if self.dropout_prob > 0:\n",
        "            conv = Dropout(self.dropout_prob)(conv)\n",
        "            \n",
        "            \n",
        "        # if max_pooling is True add a MaxPooling2D with 2x2 pool_size\n",
        "        if self.max_pooling:\n",
        "            next_layer = MaxPooling2D(2,2)(conv)\n",
        "            \n",
        "        else:\n",
        "            next_layer = conv\n",
        "            \n",
        "        skip_connection = conv\n",
        "        \n",
        "        return next_layer, skip_connection\n",
        "    \n",
        "    def upsampling_block(self,expansive_input, contractive_input, n_filters=32):\n",
        "        \"\"\"\n",
        "        Convolutional upsampling block\n",
        "        \n",
        "        Arguments:\n",
        "            expansive_input -- Input tensor from previous layer\n",
        "            contractive_input -- Input tensor from previous skip layer\n",
        "            n_filters -- Number of filters for the convolutional layers\n",
        "        Returns: \n",
        "            conv -- Tensor output\n",
        "        \"\"\"\n",
        "        self.expansive_inp = expansive_input\n",
        "        self.conc_inp = contractive_input\n",
        "        self.n_filt = n_filters\n",
        "\n",
        "        up = Conv2DTranspose(\n",
        "                    self.n_filt,   \n",
        "                    3,    \n",
        "                    strides=(2,2),\n",
        "                    padding='same')(self.expansive_inp)\n",
        "        \n",
        "        # Merge the previous output and the contractive_input\n",
        "        merge = concatenate([up, self.conc_inp], axis=3)\n",
        "        conv = Conv2D(self.n_filt,   \n",
        "                    3,    \n",
        "                    activation='relu',\n",
        "                    padding='same',\n",
        "                    kernel_initializer='he_normal')(merge)\n",
        "        conv = Conv2D(self.n_filt,  \n",
        "                    3,   \n",
        "                    activation='relu',\n",
        "                    padding='same',\n",
        "                    kernel_initializer='he_normal')(conv)\n",
        "        \n",
        "        return conv\n",
        "\n",
        "block = Blocks()\n",
        "\n",
        "class Unet:\n",
        "    def unet_model(self,input_size=(96, 128, 3), n_filters=32, n_classes=5):\n",
        "        \"\"\"\n",
        "        Unet model\n",
        "        \n",
        "        Arguments:\n",
        "            input_size -- Input shape \n",
        "            n_filters -- Number of filters for the convolutional layers\n",
        "            n_classes -- Number of output classes\n",
        "        Returns: \n",
        "            model -- tf.keras.Model\n",
        "        \"\"\"\n",
        "        # self.input_size = input_size\n",
        "        # self.n_filters = n_filters\n",
        "        # self.n_classes = n_classes\n",
        "\n",
        "        inputs = Input(input_size)\n",
        "        \n",
        "        # Contracting Path (encoding)\n",
        "        # Add a conv_block with the inputs of the unet_ model and n_filters\n",
        "    \n",
        "        cblock1 = block.conv_block(inputs=inputs, n_filters=n_filters)\n",
        "        # Chain the first element of the output of each block to be the input of the next conv_block. \n",
        "        # Double the number of filters at each new step\n",
        "        cblock2 = block.conv_block(cblock1[0], n_filters=n_filters*2)\n",
        "        cblock3 = block.conv_block(cblock2[0], n_filters=n_filters*4)\n",
        "        cblock4 = block.conv_block(cblock3[0], n_filters=n_filters*8, dropout_prob=0.3) # Include a dropout_prob of 0.3 for this layer\n",
        "        # Include a dropout_prob of 0.3 for this layer, and avoid the max_pooling layer\n",
        "        cblock5 = block.conv_block(cblock4[0], n_filters=n_filters*16, dropout_prob=0.3, max_pooling=False) \n",
        "        \n",
        "        \n",
        "        # Expanding Path (decoding)\n",
        "        # Add the first upsampling_block.\n",
        "        # Use the cblock5[0] as expansive_input and cblock4[1] as contractive_input and n_filters * 8\n",
        "        \n",
        "        ublock6 = block.upsampling_block(cblock5[0], cblock4[1],  n_filters= n_filters*8)\n",
        "        # Chain the output of the previous block as expansive_input and the corresponding contractive block output.\n",
        "        # Note that you must use the second element of the contractive block i.e before the maxpooling layer. \n",
        "        # At each step, use half the number of filters of the previous block \n",
        "        ublock7 = block.upsampling_block(ublock6, cblock3[1],  n_filters= n_filters*4)\n",
        "        ublock8 = block.upsampling_block(ublock7, cblock2[1],  n_filters= n_filters*2)\n",
        "        ublock9 =block.upsampling_block(ublock8, cblock1[1],  n_filters= n_filters)\n",
        "        \n",
        "\n",
        "        conv9 = Conv2D( n_filters,\n",
        "                    3,\n",
        "                    activation='relu',\n",
        "                    padding='same',\n",
        "                    kernel_initializer='he_normal')(ublock9)\n",
        "\n",
        "        # Add a Conv2D layer with n_classes filter, kernel size of 1 and a 'same' padding\n",
        "        \n",
        "        conv10 = Conv2D(n_classes, 1, padding='same')(conv9)\n",
        "        \n",
        "        \n",
        "        model = tf.keras.Model(inputs=inputs, outputs=conv10)\n",
        "\n",
        "        return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from dataclasses import dataclass\n",
        "@dataclass\n",
        "class ModelDimensionConfig:\n",
        "    img_height = 96\n",
        "    img_width = 128\n",
        "    num_channels = 3\n",
        "\n",
        "    EPOCHS = 100\n",
        "    VAL_SUBSPLITS = 5\n",
        "    BUFFER_SIZE = 500\n",
        "    BATCH_SIZE = 32\n",
        "\n",
        "class ModelTrainer:\n",
        "    def __init__(self):\n",
        "        # self.model_trainer_config = ModelTrainerConfig()\n",
        "        self.dimension = ModelDimensionConfig()\n",
        "\n",
        "    def initialize_training(self,train_dataset,epoch):\n",
        "        unet = Unet.unet_model((self.dimension.img_height,self.dimension.img_width,self.dimension.num_channels))\n",
        "\n",
        "        unet.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "        \n",
        "        unet.fit(train_dataset,epoch)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "unets = Unet()\n",
        "unets = unets.unet_model()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "unets.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 239,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "5/7 [====================>.........] - ETA: 1s - loss: 0.9834 - accuracy: 0.6458"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[239], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m unets\u001b[39m.\u001b[39;49mfit(train_dataset,epochs\u001b[39m=\u001b[39;49mEPOCHS)\n",
            "File \u001b[0;32m~/tensorflow-test/env/lib/python3.9/site-packages/keras/utils/traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 64\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
            "File \u001b[0;32m~/tensorflow-test/env/lib/python3.9/site-packages/keras/engine/training.py:1409\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1402\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[1;32m   1403\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m   1404\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[1;32m   1405\u001b[0m     step_num\u001b[39m=\u001b[39mstep,\n\u001b[1;32m   1406\u001b[0m     batch_size\u001b[39m=\u001b[39mbatch_size,\n\u001b[1;32m   1407\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[1;32m   1408\u001b[0m   callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1409\u001b[0m   tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[1;32m   1410\u001b[0m   \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[1;32m   1411\u001b[0m     context\u001b[39m.\u001b[39masync_wait()\n",
            "File \u001b[0;32m~/tensorflow-test/env/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
            "File \u001b[0;32m~/tensorflow-test/env/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    912\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    914\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 915\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    917\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    918\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
            "File \u001b[0;32m~/tensorflow-test/env/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    944\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m    945\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    946\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 947\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_stateless_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    948\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    949\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    950\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[1;32m    951\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
            "File \u001b[0;32m~/tensorflow-test/env/lib/python3.9/site-packages/tensorflow/python/eager/function.py:2453\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2450\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m   2451\u001b[0m   (graph_function,\n\u001b[1;32m   2452\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2453\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[1;32m   2454\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
            "File \u001b[0;32m~/tensorflow-test/env/lib/python3.9/site-packages/tensorflow/python/eager/function.py:1860\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1856\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1857\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1858\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1859\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1860\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[1;32m   1861\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[1;32m   1862\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1863\u001b[0m     args,\n\u001b[1;32m   1864\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1865\u001b[0m     executing_eagerly)\n\u001b[1;32m   1866\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
            "File \u001b[0;32m~/tensorflow-test/env/lib/python3.9/site-packages/tensorflow/python/eager/function.py:497\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    495\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[1;32m    496\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 497\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[1;32m    498\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[1;32m    499\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[1;32m    500\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[1;32m    501\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[1;32m    502\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[1;32m    503\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    504\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    505\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[1;32m    506\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    509\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[1;32m    510\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
            "File \u001b[0;32m~/tensorflow-test/env/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 54\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[1;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     56\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     57\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "unets.fit(train_dataset,epochs=EPOCHS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.15"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
